## 人工智慧教學地圖
#### 歷史
人工智慧的歷史源遠流長。在古代的神話傳說中，技藝高超的工匠可以製作人造人，並為其賦予智能或意識。

現代意義上的AI始於古典哲學家用機械符號處理的觀點解釋人類思考過程的嘗試。

20世紀40年代基於抽象數學推理的可程式數字電腦的發明使一批科學家開始嚴肅地探討構造一個電子大腦的可能性。

早期人工智慧偏重於 搜尋求解 與 邏輯推論 ，並且在 優化算法 / 電腦下棋 / 專家系統 等等領域有不錯的表現，因此研究成果也相對集中在這些領域。

例如在 1997 年，IBM 的深藍程式，挑戰當時的西洋棋王 Garry Kasparov 並且獲勝，就展現了電腦在下棋領域的強大能力！

1995 年開始由於 Web 網路的進展快速，開放資料很多，Google 等 搜尋引擎 公司異軍突起，於是 大數據 這類的技術開始萌芽。

有了足夠的資料之後，就能採用 機率統計 的方法進行決策，於是 馬可夫鏈 / 隱馬可夫模型 / 貝氏網路 / 支持向量機 等方法開始嶄露頭角，這些方法被用在 資料挖礦 / 模式識別 / 統計語言學 等領域。

#### 簡介
* 相關領域
由於《深度學習》的技術突破，這幾年《人工智慧》當紅，大學也相繼開設了很多相關課程，像是 機器學習 、 深度學習 、 資料科學 、 資料挖礦 等等。

人工智慧領域很大，老師們往往只專長一個主題，因此光是《人工智慧》一門課不容易全面涵蓋。

我的教學會選擇從最簡單的 爬山演算法 開始，讓學員知道《人工智慧程式也可以很簡單》，然後再轉到 梯度下降法 與 反傳遞演算法 ，這兩個算法是 神經網路 與 深度學習 的基礎。

然後開始學習傳統人工智慧方法，包含 圖形搜尋 / 邏輯推論 等主題。

接著加強《數學基礎》，開始透過 科學計算 熟悉如何用 Python 實作《機率 / 統計 / 向量 / 矩陣 / 代數 / 幾何 / 微積分》等領域的程式。

最後進入 機器學習 領域，包含 統計學習 / 模式識別 / 深度學習 等等。

學習了一些方法後，我們會穿插進入應用主題，像是 語言處理 / 影像處理 / 機器人 等主題。

#### 使用者體驗(UX)
* 簡介
由美國學者唐·諾曼提出，所以他共同創辦的尼爾森諾曼集團給的總結定義是最核心的概念。該定義說「使用者經驗」包含使用者與公司的產品與服務互動中的所有面向。

其中最重要的概念就是以使用者為中心去思考人機互動，所以和優使性強調以完成工作為主的物的思維是不同的。早期的優使性，強調物在任務中的學習性、效能和效率、記憶性及記憶延續性、錯誤率及錯誤承受能力。

* 概述
使用者體驗是指一個人使用一個特定產品或系統或服務時的行為、情緒與態度。包括人機互動與擁有產品時的操作面向、體驗面向、情感面向、意義面向、與價值面向；還包含使用者對於系統的功能、易用、效率的感受，因此使用者經驗在本質上可以視為一個人對於系統的主觀感受與主觀想法。

使用者經驗是動態的，由於不斷變化的使用情況、不停變化的各個系統，以及變化發生背後的情境與脈絡，因此它是不斷隨著時間而變化。總而言之，使用者經驗是關於使用者如何和產品互動及體驗產品。

* 案例
    * 註冊 Sign up / Registration
    Zeplin, Connected space for product teams:
    不論任何產品，註冊幾乎是必備流程。在個人註冊過這麼多產品後，Zeplin算是數一數二流暢又讓人愉悅的。仔細觀察簡單的註冊畫面。
    
    它包含：
    * 即時反饋 Instant feedback
    不論是成功或是輸入錯誤，Zeplin利用顏色及圖示告知使用者目前的狀態

    * 鼓勵語氣 Encouraging tone
    當輸入完畢時，「不錯喲 Looks good！」、「讚喔Aweome！」，右方的確認訊息十分正面，肯定使用者的輸入動作，讓用戶感覺良好

    * 提供有用的資訊Informative message
    當在輸入電子郵件、名稱及密碼時，同時提供使用者相關資訊

* 參考資訊
[參考資料](https://medium.com/uxeastmeetswest/%E5%A5%BDux%E8%A8%AD%E8%A8%88%E6%A1%88%E4%BE%8B%E5%88%86%E4%BA%AB-%E4%B8%8A-%E4%B8%83%E5%A4%A7%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%E6%83%85%E5%A2%83-good-ux-design-examples-7-basic-user-scenarios-bcd9fe0f22e4)


## 爬山演算法
* 概念
    * 一種優化算法
    * 往高的地方爬
    * 以左右高度來做判斷，比較高度來持續攀升

* 演算法(框架)
反覆的作這樣的動作，直到旁邊的解都比現在的更差時，程式就停止。

```
Algorithm HillClimbing(f, x)
  x = 隨意設定一個解。
  while (x 有鄰居 x' 比 x 更高)
    x = x';
  end
  return x;
end
```

* 程式碼
>>HillClimbingSimple.py
```
def hillClimbing(f, x, dx=0.01):
    while (True):
        print('x={0:.3f} f(x)={1:.3f}'.format(x, f(x)))
        if f(x+dx)>f(x):
            x = x + dx
        elif f(x-dx)>f(x):
            x = x - dx
        else:
            break
    return x

def f(x):
    return -1*(x*x+3*x+5)

hillClimbing(f, 0)
```
* 執行結果
以-1*(x*x-2*x+1)為函數
```
user@LAPTOP-8K49E37L MINGW64 ~/Desktop/人工智慧/teaching/ai/02-optimize/01-hillclimbing/02-var1 (master)
$ python hillClimbing1.py
x=0.00000 f(x)=-1.00000
x=0.01000 f(x)=-0.98010
x=0.02000 f(x)=-0.96040
x=0.03000 f(x)=-0.94090
x=0.04000 f(x)=-0.92160
x=0.05000 f(x)=-0.90250
x=0.06000 f(x)=-0.88360
x=0.07000 f(x)=-0.86490
x=0.08000 f(x)=-0.84640
x=0.09000 f(x)=-0.82810
x=0.10000 f(x)=-0.81000
x=0.11000 f(x)=-0.79210
x=0.12000 f(x)=-0.77440
x=0.13000 f(x)=-0.75690
x=0.14000 f(x)=-0.73960
x=0.15000 f(x)=-0.72250
x=0.16000 f(x)=-0.70560
x=0.17000 f(x)=-0.68890
x=0.18000 f(x)=-0.67240
x=0.19000 f(x)=-0.65610
x=0.20000 f(x)=-0.64000
x=0.21000 f(x)=-0.62410
x=0.22000 f(x)=-0.60840
x=0.23000 f(x)=-0.59290
x=0.24000 f(x)=-0.57760
x=0.25000 f(x)=-0.56250
x=0.26000 f(x)=-0.54760
x=0.27000 f(x)=-0.53290
x=0.28000 f(x)=-0.51840
x=0.29000 f(x)=-0.50410
x=0.30000 f(x)=-0.49000
x=0.31000 f(x)=-0.47610
x=0.32000 f(x)=-0.46240
x=0.33000 f(x)=-0.44890
x=0.34000 f(x)=-0.43560
x=0.35000 f(x)=-0.42250
x=0.36000 f(x)=-0.40960
x=0.37000 f(x)=-0.39690
x=0.38000 f(x)=-0.38440
x=0.39000 f(x)=-0.37210
x=0.40000 f(x)=-0.36000
x=0.41000 f(x)=-0.34810
x=0.42000 f(x)=-0.33640
x=0.43000 f(x)=-0.32490
x=0.44000 f(x)=-0.31360
x=0.45000 f(x)=-0.30250
x=0.46000 f(x)=-0.29160
x=0.47000 f(x)=-0.28090
x=0.48000 f(x)=-0.27040
x=0.49000 f(x)=-0.26010
x=0.50000 f(x)=-0.25000
x=0.51000 f(x)=-0.24010
x=0.52000 f(x)=-0.23040
x=0.53000 f(x)=-0.22090
x=0.54000 f(x)=-0.21160
x=0.55000 f(x)=-0.20250
x=0.56000 f(x)=-0.19360
x=0.57000 f(x)=-0.18490
x=0.58000 f(x)=-0.17640
x=0.59000 f(x)=-0.16810
x=0.60000 f(x)=-0.16000
x=0.61000 f(x)=-0.15210
x=0.62000 f(x)=-0.14440
x=0.63000 f(x)=-0.13690
x=0.64000 f(x)=-0.12960
x=0.65000 f(x)=-0.12250
x=0.66000 f(x)=-0.11560
x=0.67000 f(x)=-0.10890
x=0.68000 f(x)=-0.10240
x=0.69000 f(x)=-0.09610
x=0.70000 f(x)=-0.09000
x=0.71000 f(x)=-0.08410
x=0.72000 f(x)=-0.07840
x=0.73000 f(x)=-0.07290
x=0.74000 f(x)=-0.06760
x=0.75000 f(x)=-0.06250
x=0.76000 f(x)=-0.05760
x=0.77000 f(x)=-0.05290
x=0.78000 f(x)=-0.04840
x=0.79000 f(x)=-0.04410
x=0.80000 f(x)=-0.04000
x=0.81000 f(x)=-0.03610
x=0.82000 f(x)=-0.03240
x=0.83000 f(x)=-0.02890
x=0.84000 f(x)=-0.02560
x=0.85000 f(x)=-0.02250
x=0.86000 f(x)=-0.01960
x=0.87000 f(x)=-0.01690
x=0.88000 f(x)=-0.01440
x=0.89000 f(x)=-0.01210
x=0.90000 f(x)=-0.01000
x=0.91000 f(x)=-0.00810
x=0.92000 f(x)=-0.00640
x=0.93000 f(x)=-0.00490
x=0.94000 f(x)=-0.00360
x=0.95000 f(x)=-0.00250
x=0.96000 f(x)=-0.00160
x=0.97000 f(x)=-0.00090
x=0.98000 f(x)=-0.00040
x=0.99000 f(x)=-0.00010
x=1.00000 f(x)=-0.00000
```
![Pic](https://github.com/brian891005/ai109b/tree/main/Note/%E5%9C%96%E7%89%87/function.jpg)
